{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5mxQZnv8qCCqOzTZ9EbPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HelloKindGit/DA_RNN_PaperReplication/blob/main/A_Dual_Stage_Attention_Based_Recurrent_Neural_Network_for_Time_Series_Prediction_NASDAQ100_Paper_Replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Project is Made in Google Colab\n",
        "- Paper: https://arxiv.org/abs/1704.02971"
      ],
      "metadata": {
        "id": "iAXu7Xwg3J0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "2_rCR02-dQ4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fd0rOsZgdJCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b93894-c9ed-4986-bfe1-96a09c1b3664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n"
          ]
        }
      ],
      "source": [
        "#Built-in libraries\n",
        "import math\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "from os import listdir\n",
        "from pathlib import Path\n",
        "from timeit import default_timer as timer \n",
        "\n",
        "#Third-party libraries for data handling and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "#PyTorch and related libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "#External PyTorch packages\n",
        "try: \n",
        "    import torchinfo\n",
        "except:\n",
        "    !pip install torchinfo\n",
        "    import torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "try: \n",
        "    import torchmetrics\n",
        "except:\n",
        "    !pip install torchmetrics\n",
        "    import torchmetrics\n",
        "from torchmetrics import MeanAbsolutePercentageError as MAPE\n",
        "\n",
        "#Extra imports\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "Vcau6etsgSkb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Import"
      ],
      "metadata": {
        "id": "w0ERCyLTdjhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NASDAQ100\n",
        "\n",
        "A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction\n",
        "Qin, Y., Song, D., Cheng, H., Cheng, W., Jiang, G., Cottrell, G.\n",
        "International Joint Conference on Artificial Intelligence (IJCAI) , 2017\n",
        "https://cseweb.ucsd.edu/~yaq007/NASDAQ100_stock_data.html"
      ],
      "metadata": {
        "id": "Sza0-otpiZkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path to data folder\n",
        "data_path = Path(\"Datasets/\")\n",
        "file_path = data_path / \"nasdaq_data\"\n",
        "\n",
        "# If the folder doesn't exist, download and extract it\n",
        "if not file_path.is_dir():\n",
        "  print(f\"Did not find {file_path} directory, creating one and downloading data...\")\n",
        "  file_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  data_url = \"https://cseweb.ucsd.edu/~yaq007/nasdaq100.zip\"\n",
        "  zip_file_path = data_path / \"nasdaq_data.zip\"\n",
        "  urllib.request.urlretrieve(data_url, zip_file_path)\n",
        "\n",
        "  print(\"Unzipping data...\") \n",
        "  with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(file_path)\n",
        "\n",
        "  os.remove(zip_file_path)\n",
        "else:\n",
        "  print(f\"{file_path} directory exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37e6SKLfeKPK",
        "outputId": "94b065ab-d74b-42b1-daac-7fbfd4cebbfb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find Datasets/nasdaq_data directory, creating one and downloading data...\n",
            "Unzipping data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/Datasets/nasdaq_data/nasdaq100/small/nasdaq100_padding.csv\")"
      ],
      "metadata": {
        "id": "qFhpWbDwet_0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "fO3GbN2oTLKV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "8db4706a-984d-4e07-d9bf-d375ee098714"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40560, 82)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       AAL   AAPL   ADBE    ADI      ADP       ADSK   AKAM     ALXN    AMAT  \\\n",
              "0  35.9800  96.80  97.80  61.15  95.4000  58.180000  58.00  127.040  26.680   \n",
              "1  35.9310  96.89  97.80  61.61  95.4115  58.190000  58.12  126.060  26.730   \n",
              "2  35.9044  96.95  97.57  61.98  95.5100  58.203333  57.95  126.510  26.712   \n",
              "3  35.8900  96.97  97.55  62.09  95.5200  58.216667  57.96  126.280  26.740   \n",
              "4  36.0080  96.96  97.73  61.89  95.5300  58.230000  58.21  126.585  26.720   \n",
              "\n",
              "       AMGN  ...    TXN    VIAB      VOD    VRTX     WBA    WDC    WFM   XLNX  \\\n",
              "0  165.8100  ...  70.73  45.230  31.1701  95.270  81.365  52.16  33.95  48.61   \n",
              "1  165.9101  ...  70.69  45.010  31.1900  94.170  81.540  52.15  34.10  48.74   \n",
              "2  166.1800  ...  71.30  45.015  31.2100  94.749  81.530  52.27  34.01  48.99   \n",
              "3  166.1480  ...  71.31  45.020  31.2100  94.310  81.710  52.30  33.96  48.95   \n",
              "4  165.9900  ...  71.06  45.050  31.1800  94.155  81.720  52.30  34.17  48.89   \n",
              "\n",
              "     YHOO       NDX  \n",
              "0  38.010  4665.054  \n",
              "1  38.140  4665.054  \n",
              "2  38.150  4665.826  \n",
              "3  38.195  4667.081  \n",
              "4  38.320  4664.491  \n",
              "\n",
              "[5 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16b3e731-4121-49d5-9406-c5785e898335\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AAL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADI</th>\n",
              "      <th>ADP</th>\n",
              "      <th>ADSK</th>\n",
              "      <th>AKAM</th>\n",
              "      <th>ALXN</th>\n",
              "      <th>AMAT</th>\n",
              "      <th>AMGN</th>\n",
              "      <th>...</th>\n",
              "      <th>TXN</th>\n",
              "      <th>VIAB</th>\n",
              "      <th>VOD</th>\n",
              "      <th>VRTX</th>\n",
              "      <th>WBA</th>\n",
              "      <th>WDC</th>\n",
              "      <th>WFM</th>\n",
              "      <th>XLNX</th>\n",
              "      <th>YHOO</th>\n",
              "      <th>NDX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35.9800</td>\n",
              "      <td>96.80</td>\n",
              "      <td>97.80</td>\n",
              "      <td>61.15</td>\n",
              "      <td>95.4000</td>\n",
              "      <td>58.180000</td>\n",
              "      <td>58.00</td>\n",
              "      <td>127.040</td>\n",
              "      <td>26.680</td>\n",
              "      <td>165.8100</td>\n",
              "      <td>...</td>\n",
              "      <td>70.73</td>\n",
              "      <td>45.230</td>\n",
              "      <td>31.1701</td>\n",
              "      <td>95.270</td>\n",
              "      <td>81.365</td>\n",
              "      <td>52.16</td>\n",
              "      <td>33.95</td>\n",
              "      <td>48.61</td>\n",
              "      <td>38.010</td>\n",
              "      <td>4665.054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35.9310</td>\n",
              "      <td>96.89</td>\n",
              "      <td>97.80</td>\n",
              "      <td>61.61</td>\n",
              "      <td>95.4115</td>\n",
              "      <td>58.190000</td>\n",
              "      <td>58.12</td>\n",
              "      <td>126.060</td>\n",
              "      <td>26.730</td>\n",
              "      <td>165.9101</td>\n",
              "      <td>...</td>\n",
              "      <td>70.69</td>\n",
              "      <td>45.010</td>\n",
              "      <td>31.1900</td>\n",
              "      <td>94.170</td>\n",
              "      <td>81.540</td>\n",
              "      <td>52.15</td>\n",
              "      <td>34.10</td>\n",
              "      <td>48.74</td>\n",
              "      <td>38.140</td>\n",
              "      <td>4665.054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.9044</td>\n",
              "      <td>96.95</td>\n",
              "      <td>97.57</td>\n",
              "      <td>61.98</td>\n",
              "      <td>95.5100</td>\n",
              "      <td>58.203333</td>\n",
              "      <td>57.95</td>\n",
              "      <td>126.510</td>\n",
              "      <td>26.712</td>\n",
              "      <td>166.1800</td>\n",
              "      <td>...</td>\n",
              "      <td>71.30</td>\n",
              "      <td>45.015</td>\n",
              "      <td>31.2100</td>\n",
              "      <td>94.749</td>\n",
              "      <td>81.530</td>\n",
              "      <td>52.27</td>\n",
              "      <td>34.01</td>\n",
              "      <td>48.99</td>\n",
              "      <td>38.150</td>\n",
              "      <td>4665.826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.8900</td>\n",
              "      <td>96.97</td>\n",
              "      <td>97.55</td>\n",
              "      <td>62.09</td>\n",
              "      <td>95.5200</td>\n",
              "      <td>58.216667</td>\n",
              "      <td>57.96</td>\n",
              "      <td>126.280</td>\n",
              "      <td>26.740</td>\n",
              "      <td>166.1480</td>\n",
              "      <td>...</td>\n",
              "      <td>71.31</td>\n",
              "      <td>45.020</td>\n",
              "      <td>31.2100</td>\n",
              "      <td>94.310</td>\n",
              "      <td>81.710</td>\n",
              "      <td>52.30</td>\n",
              "      <td>33.96</td>\n",
              "      <td>48.95</td>\n",
              "      <td>38.195</td>\n",
              "      <td>4667.081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36.0080</td>\n",
              "      <td>96.96</td>\n",
              "      <td>97.73</td>\n",
              "      <td>61.89</td>\n",
              "      <td>95.5300</td>\n",
              "      <td>58.230000</td>\n",
              "      <td>58.21</td>\n",
              "      <td>126.585</td>\n",
              "      <td>26.720</td>\n",
              "      <td>165.9900</td>\n",
              "      <td>...</td>\n",
              "      <td>71.06</td>\n",
              "      <td>45.050</td>\n",
              "      <td>31.1800</td>\n",
              "      <td>94.155</td>\n",
              "      <td>81.720</td>\n",
              "      <td>52.30</td>\n",
              "      <td>34.17</td>\n",
              "      <td>48.89</td>\n",
              "      <td>38.320</td>\n",
              "      <td>4664.491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 82 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16b3e731-4121-49d5-9406-c5785e898335')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16b3e731-4121-49d5-9406-c5785e898335 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16b3e731-4121-49d5-9406-c5785e898335');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"AAPL\"].plot()"
      ],
      "metadata": {
        "id": "FjZ7rsa9si_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "fefef376-f7fb-4d77-e91b-04996110f53b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#original numbers from paper\n",
        "num_timesteps = 10\n",
        "train_length = 35100\n",
        "val_length = 2730 #test_length = 2730 -> which means the rest\n",
        "target_col = \"AAPL\" #prediction of AAPL data in NASDAQ100\n",
        "target_shift = -1\n",
        "\n",
        "#Generate X and y datasets\n",
        "#formt eine Zeitreihe in ein Format um, das zum Trainieren eines Modells geeignet ist, um 'AAPL' einen Schritt (target_shift) in die Zukunft vorherzusagen; basierend auf den letzten 10 Zeitschritten (num_timesteps) aller Spalten\n",
        "X = np.stack([data.loc[:, data.columns!=target_col].shift(num_timesteps - t - 1).fillna(method=\"bfill\").values for t in range(num_timesteps)], axis=1)\n",
        "y_h = np.stack([data[target_col].shift(num_timesteps - t - 1).fillna(method=\"bfill\").values for t in range(num_timesteps)], axis=1)\n",
        "y_h = np.expand_dims(y_h, axis=-1)\n",
        "target = data[target_col].shift(target_shift).fillna(method=\"ffill\").values\n",
        "\n",
        "# Define split function\n",
        "def split_and_normalize(data):\n",
        "    data_split = np.split(data, [train_length, train_length + val_length])\n",
        "    \n",
        "    #min/max from train split\n",
        "    data_min, data_max = data_split[0].min(axis=0), data_split[0].max(axis=0)\n",
        "\n",
        "    data_norm = [(part - data_min) / (data_max - data_min) for part in data_split]\n",
        "    data_norm = [torch.Tensor(part) for part in data_norm]\n",
        "    \n",
        "    return data_norm\n",
        "\n",
        "# Split and normalize datasets\n",
        "X_train_t, X_val_t, X_test_t = split_and_normalize(X)\n",
        "y_h_train_t, y_h_val_t, y_h_test_t = split_and_normalize(y_h)\n",
        "target_train_t, target_val_t, target_test_t = split_and_normalize(target)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(TensorDataset(X_train_t, y_h_train_t, target_train_t), shuffle=False, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(TensorDataset(X_val_t, y_h_val_t, target_val_t), shuffle=False, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(TensorDataset(X_test_t, y_h_test_t, target_test_t), shuffle=False, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "JX4ikRFqsuSX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t.shape, X_val_t.shape, X_test_t.shape, y_h_train_t.shape, y_h_val_t.shape, y_h_test_t.shape, target_train_t.shape, target_val_t.shape, target_test_t.shape"
      ],
      "metadata": {
        "id": "X6n5YRC_s_lV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44486cd-26a1-4115-f892-88b0ae94a246"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([35100, 10, 81]),\n",
              " torch.Size([2730, 10, 81]),\n",
              " torch.Size([2730, 10, 81]),\n",
              " torch.Size([35100, 10, 1]),\n",
              " torch.Size([2730, 10, 1]),\n",
              " torch.Size([2730, 10, 1]),\n",
              " torch.Size([35100]),\n",
              " torch.Size([2730]),\n",
              " torch.Size([2730]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling data to original values -> this will be needed for the plotting later on\n",
        "data_split = np.split(target, [train_length, train_length + val_length])\n",
        "#min/max from the training part of the split\n",
        "target_train_min, target_train_max = data_split[0].min(axis=0), data_split[0].max(axis=0)\n",
        "print(target_train_min, target_train_max)"
      ],
      "metadata": {
        "id": "e4x4AqZpQJ4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f69b11-ca07-49ed-bd34-7822e95da32b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96.435 118.6285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "- There are 2 similar Models:\n",
        "  - A Model with Parameters (nn.Parameter()) -> Doesn't work well for the Predictions (should not be used in this state)\n",
        "  - A Model with Linear Layers (nn.Linear())\n",
        "- The Model with the Linear Layers is the improved Version from the Model with Parameters with the Help from ChatGTP"
      ],
      "metadata": {
        "id": "zQ67v1u4eqjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder / Decoder - Model with Parameters"
      ],
      "metadata": {
        "id": "3Dz9YWcLfUTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputAttention(nn.Module):\n",
        "  def __init__(self, T, N, M):\n",
        "    super(InputAttention, self).__init__()\n",
        "\n",
        "    self.T = T #number of time steps in the window T\n",
        "    self.N = N #LSTM input_size\n",
        "    self.M = M #size of hidden states for the encoder\n",
        "\n",
        "    self.v_e = nn.Parameter(torch.zeros((self.T, 1)))\n",
        "    self.W_e = nn.Parameter(torch.zeros((2 * self.M, self.T)))\n",
        "    self.U_e = nn.Parameter(torch.zeros((self.T, self.T)))\n",
        "\n",
        "    self.lstm = nn.LSTMCell(input_size=self.N, hidden_size=self.M)\n",
        "\n",
        "  def forward(self, X):\n",
        "    batch_size = X.size(0)\n",
        "    hidden = torch.zeros((batch_size, self.M)).to(device)\n",
        "    cell = torch.zeros((batch_size, self.M)).to(device)\n",
        "\n",
        "    encode = torch.zeros((batch_size, self.T, self.M))\n",
        "\n",
        "    for t in range(self.T):\n",
        "      h_c = torch.cat((hidden, cell), dim=1)\n",
        "\n",
        "      a = (h_c @ self.W_e).unsqueeze(1).expand(-1, self.N, -1)\n",
        "      b = X.permute(0, 2, 1) @ self.U_e\n",
        "      \n",
        "      e_t = (torch.tanh(a + b) @ self.v_e).squeeze()\n",
        "      a_t = torch.softmax(e_t, dim=1)\n",
        "\n",
        "      attention_weighted_inputs = a_t * X[:, t, :]\n",
        "\n",
        "      hidden, cell = self.lstm(attention_weighted_inputs, (hidden, cell))\n",
        "\n",
        "      encode[:, t, :] = hidden\n",
        "    return encode\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, T, N, M):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.input_attention = InputAttention(T, N, M).to(device)\n",
        "\n",
        "  def forward(self, X):\n",
        "    encoded_X = self.input_attention(X)\n",
        "    return encoded_X\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "class TemporalAttention(nn.Module):\n",
        "  def __init__(self, T, P, M):\n",
        "    super(TemporalAttention, self).__init__()\n",
        "    self.T = T #number of time steps in the window T\n",
        "    self.P = P #size of hidden states for the decoder\n",
        "    self.M = M #size of hidden states for the encoder\n",
        "\n",
        "    self.v_d = nn.Parameter(torch.zeros((self.M, 1)))\n",
        "    self.W_d = nn.Parameter(torch.zeros((2*self.P, self.M)))\n",
        "    self.U_d = nn.Parameter(torch.zeros((self.M, self.M)))\n",
        "\n",
        "    self.w_tilde = nn.Parameter(torch.zeros((self.M+1, 1)))\n",
        "    self.W_y = nn.Parameter(torch.zeros((self.P + self.M, self.P)))\n",
        "    self.v_y = nn.Parameter(torch.zeros((self.P, 1)))\n",
        "\n",
        "    self.b_tilde = nn.Parameter(torch.zeros((1, 1)))\n",
        "    self.b_w = nn.Parameter(torch.zeros(1, self.P))\n",
        "    self.b_v = nn.Parameter(torch.zeros((1, 1)))\n",
        "    \n",
        "    self.lstm = nn.LSTMCell(input_size=1, hidden_size=self.P)\n",
        "\n",
        "  def forward(self, encoded_x, y):\n",
        "    batch_size = encoded_x.size(0)\n",
        "\n",
        "    hidden = torch.zeros((batch_size, self.P)).to(device)\n",
        "    cell = torch.zeros((batch_size, self.P)).to(device)\n",
        "\n",
        "    for t in range(self.T):\n",
        "      d_s = torch.cat((hidden, cell), dim=1)\n",
        "\n",
        "      a = (d_s @ self.W_d).unsqueeze(1).expand(-1, encoded_x.size(1), -1)\n",
        "      b = encoded_x @ self.U_d\n",
        "      \n",
        "      l_t = torch.tanh(a + b) @ self.v_d\n",
        "      b_t = torch.softmax(l_t, dim=1)\n",
        "      c_t = torch.sum(b_t * encoded_x, dim=1)\n",
        "\n",
        "      ct_yt_concat = torch.cat((c_t, y[:, t, :]), dim=1)\n",
        "      y_t_tilde = ct_yt_concat @ self.w_tilde + self.b_tilde\n",
        "      hidden, cell = self.lstm(y_t_tilde, (hidden, cell))\n",
        "    \n",
        "    hidden_ct_concat = torch.cat((hidden, c_t), dim=1)\n",
        "    c = (hidden_ct_concat @ self.W_y + self.b_w)\n",
        "    y_T = c @ self.v_y + self.b_v\n",
        "    return y_T\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, T, P, M):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.temporal_attention = TemporalAttention(T, P, M)\n",
        "\n",
        "  def forward(self, X_tilde, y):\n",
        "    y_decoded = self.temporal_attention(X_tilde, y).to(device)\n",
        "    return y_decoded"
      ],
      "metadata": {
        "id": "_MIVg0P_htRe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder / Decoder - Model with Linear Layers"
      ],
      "metadata": {
        "id": "8rwpMh-yLkXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputAttention(nn.Module):\n",
        "  def __init__(self, T, N, M):\n",
        "    super(InputAttention, self).__init__()\n",
        "\n",
        "    self.T = T #number of time steps in the window T\n",
        "    self.N = N #LSTM input_size\n",
        "    self.M = M #size of hidden states for the encoder\n",
        "\n",
        "    self.v_e = nn.Linear(in_features=self.T, out_features=1)\n",
        "    self.W_e = nn.Linear(in_features=2 * self.M, out_features=self.T)\n",
        "    self.U_e = nn.Linear(in_features=self.T, out_features=self.T)\n",
        "\n",
        "    self.lstm = nn.LSTMCell(input_size=self.N, hidden_size=self.M)\n",
        "\n",
        "  def forward(self, X):\n",
        "    batch_size = X.size(0)\n",
        "    hidden = torch.zeros((batch_size, self.M)).to(device)\n",
        "    cell = torch.zeros((batch_size, self.M)).to(device)\n",
        "\n",
        "    encode = torch.zeros((batch_size, self.T, self.M))\n",
        "\n",
        "    for t in range(self.T):\n",
        "      h_c = torch.cat((hidden, cell), dim=1)\n",
        "\n",
        "      a = self.W_e(h_c).unsqueeze(1).expand(-1, self.N, -1)\n",
        "      b = self.U_e(X.permute(0, 2, 1))\n",
        "      \n",
        "      e_t = self.v_e(torch.tanh(a + b)).squeeze()\n",
        "      a_t = torch.softmax(e_t, dim=1)\n",
        "\n",
        "      hidden, cell = self.lstm(a_t * X[:, t, :], (hidden, cell))\n",
        "\n",
        "      encode[:, t, :] = hidden\n",
        "    return encode\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, T, N, M):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.input_attention = InputAttention(T, N, M)\n",
        "\n",
        "  def forward(self, X):\n",
        "    encoded_X = self.input_attention(X)\n",
        "    return encoded_X\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "class TemporalAttention(nn.Module):\n",
        "  def __init__(self, T, P, M):\n",
        "    super(TemporalAttention, self).__init__()\n",
        "    self.T = T #number of time steps in the window T\n",
        "    self.P = P #size of hidden states for the decoder\n",
        "    self.M = M #size of hidden states for the encoder\n",
        "\n",
        "    self.v_d = nn.Linear(in_features=self.M, out_features=1)\n",
        "    self.W_d = nn.Linear(in_features=2*self.P, out_features=self.M)\n",
        "    self.U_d = nn.Linear(in_features=self.M, out_features=self.M)\n",
        "\n",
        "    self.w_tilde = nn.Linear(in_features=self.M + 1, out_features=1)\n",
        "    self.W_y = nn.Linear(in_features=self.P + self.M, out_features=self.P)\n",
        "    self.v_y = nn.Linear(in_features=self.P, out_features=1)\n",
        "    \n",
        "    self.lstm = nn.LSTMCell(input_size=1, hidden_size=self.P)\n",
        "\n",
        "  def forward(self, encoded_x, y):\n",
        "    batch_size = encoded_x.size(0)\n",
        "\n",
        "    hidden = torch.zeros((batch_size, self.P)).to(device)\n",
        "    cell = torch.zeros((batch_size, self.P)).to(device)\n",
        "\n",
        "    for t in range(self.T):\n",
        "      d_s = torch.cat((hidden, cell), dim=1)\n",
        "\n",
        "      a = self.W_d(d_s).unsqueeze(1).expand(-1, encoded_x.size(1), -1)\n",
        "      b = self.U_d(encoded_x)\n",
        "      \n",
        "      l_t = self.v_d(torch.tanh(a + b))\n",
        "      b_t = torch.softmax(l_t, dim=1)\n",
        "      c_t = torch.sum(b_t * encoded_x, dim=1)\n",
        "\n",
        "      ct_yt_concat = torch.cat((c_t, y[:, t, :]), dim=1)\n",
        "      y_t_tilde = self.w_tilde(ct_yt_concat)\n",
        "      hidden, cell = self.lstm(y_t_tilde, (hidden, cell))\n",
        "    \n",
        "    hidden_ct_concat = torch.cat((hidden, c_t), dim=1)\n",
        "    c = self.W_y(hidden_ct_concat)\n",
        "    y_T = self.v_y(c)\n",
        "    return y_T\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, T, P, M):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.temporal_attention = TemporalAttention(T, P, M)\n",
        "\n",
        "  def forward(self, X_tilde, y):\n",
        "    y_decoded = self.temporal_attention(X_tilde, y)\n",
        "    return y_decoded"
      ],
      "metadata": {
        "id": "XT-M-JulLj4H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Complete Model\n",
        "class DualStage_Attention_RNN(nn.Module):\n",
        "  def __init__(self, N, M, P, T):\n",
        "    super(DualStage_Attention_RNN, self).__init__()\n",
        "\n",
        "    self.N = N #LSTM input_size\n",
        "    self.M = M #size of hidden states for the encoder\n",
        "    self.P = P #size of hidden states for the decoder\n",
        "    self.T = T #number of time steps in the window T\n",
        "\n",
        "    self.encoder = Encoder(T, N, M).to(device)\n",
        "    self.decoder = Decoder(T, P, M).to(device)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    encoded_X = self.encoder(x)\n",
        "    output = self.decoder(encoded_X, y)\n",
        "    #print('Final Output Shape', output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "RbrFWVlleuGl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "rrog_7XQodXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dsa_rnn_model = DualStage_Attention_RNN(81, 64, 64, 10)\n",
        "summary(dsa_rnn_model, [(128, 10, 81), (128, 10, 1)]) #test pass through of an example input"
      ],
      "metadata": {
        "id": "7ej0TB_focsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_model_summary(model):\n",
        "    table = PrettyTable([\"Layer\", \"Size\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    print(\"Model Summary:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        if not param.requires_grad:\n",
        "            continue\n",
        "        size = param.size()\n",
        "        params = param.numel()\n",
        "        table.add_row([name, size, params])\n",
        "        total_params += params\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "print_model_summary(dsa_rnn_model)"
      ],
      "metadata": {
        "id": "E4vm_Z6wz7Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tensorboard Tracking\n",
        "def create_writer(experiment_name: str, \n",
        "                  model_name: str, \n",
        "                  extra: str=None):\n",
        "  timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "  log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "  if extra:\n",
        "      log_dir = os.path.join(log_dir, extra)\n",
        "      \n",
        "  print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
        "  return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "ghIscCueuId5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Saving Model\n",
        "#https://www.learnpytorch.io/05_pytorch_going_modular/#5-creating-a-function-to-save-the-model-utilspy\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "  #Create target directory\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "\n",
        "  #Create model save path\n",
        "  if not model_name.endswith(\".pth\") and not model_name.endswith(\".pt\"):\n",
        "    raise ValueError(\"model_name should end with '.pt' or '.pth'\")\n",
        "  model_save_path = target_dir_path / model_name\n",
        "\n",
        "  #Save the model state_dict()\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "id": "LFZWkdvkgLjw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fitting"
      ],
      "metadata": {
        "id": "uUDDs3-hgFKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Loop\n",
        "def training(model: torch.nn.Module, \n",
        "             dataloader: torch.utils.data.DataLoader, \n",
        "             loss_fn: torch.nn.Module, \n",
        "             optimizer: torch.optim.Optimizer,\n",
        "             eval_metrics):\n",
        "  #train mode\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "\n",
        "  #metrics\n",
        "  train_metrics = [0, 0, 0]\n",
        "  \n",
        "  for batch, (X, y_h, y) in enumerate(dataloader):\n",
        "    X, y_h, y = X.to(device), y_h.to(device), y.to(device)\n",
        "\n",
        "    y_preds = model(X, y_h).squeeze(1)\n",
        "\n",
        "    loss = loss_fn(y_preds, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    for i, t_met in enumerate(eval_metrics):\n",
        "      err = t_met(y_preds, y)\n",
        "      train_metrics[i] += err.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  for i in range(len(train_metrics)):\n",
        "    train_metrics[i] /= len(dataloader)\n",
        "\n",
        "  train_loss /= len(dataloader)\n",
        "  return train_loss, train_metrics"
      ],
      "metadata": {
        "id": "ADu_IbuOgJOg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Validation Loop\n",
        "def validating(model: torch.nn.Module, \n",
        "               dataloader: torch.utils.data.DataLoader, \n",
        "               loss_fn: torch.nn.Module,\n",
        "               eval_metrics):\n",
        "  #eval mode\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "\n",
        "  #metrics\n",
        "  val_metrics = [0, 0, 0]\n",
        "  \n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y_h, y) in enumerate(dataloader):\n",
        "      X, y_h, y = X.to(device), y_h.to(device), y.to(device)\n",
        "\n",
        "      val_preds = model(X, y_h).squeeze(1)\n",
        "\n",
        "      loss = loss_fn(val_preds, y)\n",
        "      val_loss += loss.item()\n",
        "\n",
        "      for i, e_met in enumerate(eval_metrics):\n",
        "        err = e_met(val_preds, y)\n",
        "        val_metrics[i] += err.item()\n",
        "\n",
        "  for i in range(len(val_metrics)):\n",
        "    val_metrics[i] /= len(dataloader)\n",
        "\n",
        "  val_loss /= len(dataloader)\n",
        "  return val_loss, val_metrics"
      ],
      "metadata": {
        "id": "YQK2dbjSgJMR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Testing Loop\n",
        "def testing(model: torch.nn.Module, \n",
        "            dataloader: torch.utils.data.DataLoader, \n",
        "            loss_fn: torch.nn.Module):\n",
        "  #eval mode\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "\n",
        "  #for plotting\n",
        "  true, preds = [], []\n",
        "  \n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y_h, y) in enumerate(dataloader):\n",
        "      X, y_h, y = X.to(device), y_h.to(device), y.to(device)\n",
        "\n",
        "      test_preds = model(X, y_h)\n",
        "\n",
        "      loss = loss_fn(test_preds.squeeze(1), y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      true.append(y.detach().cpu().numpy())\n",
        "      preds.append(test_preds.detach().cpu().numpy())\n",
        "\n",
        "  out_true, out_preds = np.concatenate(true), np.concatenate(preds)\n",
        "      \n",
        "  test_loss /= len(dataloader)\n",
        "  return test_loss, out_true, out_preds"
      ],
      "metadata": {
        "id": "qPAfsin3qdOE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Main Fit Loop\n",
        "def fit(model: torch.nn.Module, \n",
        "        train_dataloader: torch.utils.data.DataLoader, \n",
        "        val_dataloader: torch.utils.data.DataLoader, \n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        lr_scheduler: torch.optim.lr_scheduler,\n",
        "        loss_fn: torch.nn.Module,\n",
        "        epochs: int,\n",
        "        eval_metrics,\n",
        "        writer: torch.utils.tensorboard.writer.SummaryWriter):\n",
        "  #result dictionary\n",
        "  results = {\n",
        "      \"train_loss\": [],\n",
        "      \"val_loss\": []\n",
        "      }\n",
        "  \n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_metrics = training(model=model,\n",
        "                          dataloader=train_dataloader,\n",
        "                          loss_fn=loss_fn,\n",
        "                          optimizer=optimizer,\n",
        "                          eval_metrics=eval_metrics)\n",
        "      \n",
        "    val_loss, val_metrics = validating(model=model,\n",
        "                        dataloader=val_dataloader,\n",
        "                        loss_fn=loss_fn,\n",
        "                        eval_metrics=eval_metrics)\n",
        "    \n",
        "    #Update learning rate\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      print(f\"Epoch: {epoch} | Train_Loss: {train_loss:.5f} | Val_Loss: {val_loss:.5f}\")\n",
        "\n",
        "    #Store losses\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"val_loss\"].append(val_loss)\n",
        "\n",
        "    #Save metrics to TensorBoard\n",
        "    if writer:\n",
        "      #Add results to SummaryWriter\n",
        "      writer.add_scalars(main_tag=\"Loss\", \n",
        "                         tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                          \"val_loss\": val_loss},\n",
        "                         global_step=epoch)\n",
        "      \n",
        "      writer.add_scalars(main_tag=\"Evaluation Metrics\", \n",
        "                         tag_scalar_dict={\"train_RMSE\": train_metrics[0],\n",
        "                                          \"train_MAE\": train_metrics[1],\n",
        "                                          \"train_MAPE\": train_metrics[2],\n",
        "                                          \"val_RMSE\": val_metrics[0],\n",
        "                                          \"val_MAE\": val_metrics[1],\n",
        "                                          \"val_MAPE\": val_metrics[2]},\n",
        "                         global_step=epoch)\n",
        "      writer.close()\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "SnkV5OvngJJk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RMSE Loss Function\n",
        "#https://discuss.pytorch.org/t/rmse-loss-function/16540/2\n",
        "def RMSELoss(y_pred,y):\n",
        "  assert y_pred.size() == y.size(), \"Expected y_pred and y to have the same size\"\n",
        "  return torch.sqrt(torch.mean((y_pred-y)**2))"
      ],
      "metadata": {
        "id": "GsN93Jyepigi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fitting\n",
        "#Set random seeds\n",
        "torch.manual_seed(10) \n",
        "torch.cuda.manual_seed(10)\n",
        "\n",
        "EPOCHS = 30 #should be at least 30-50 epochs to see actual results\n",
        "\n",
        "N = X_train_t.shape[2] #81\n",
        "M = P = 64 #or 128\n",
        "T = 10 #Dataset 'num_timesteps' would need to be changed first before T can be changed\n",
        "\n",
        "#Instantiate the model\n",
        "dsa_rnn_model = DualStage_Attention_RNN(N, M, P, T).to(device)\n",
        "\n",
        "#Define loss function and optimizer with learning rate decay\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(params=dsa_rnn_model.parameters(), lr=0.001)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=15, gamma=0.8) #in the paper it's 10 % every 10.000 iterations\n",
        "\n",
        "#Evaluation Metrics\n",
        "eval_metrics = [RMSELoss, nn.L1Loss(), MAPE()]\n",
        "\n",
        "#Start timer\n",
        "start = timer()\n",
        "\n",
        "#Fit model\n",
        "model_results = fit(model=dsa_rnn_model, \n",
        "                    train_dataloader=train_dataloader,\n",
        "                    val_dataloader=val_dataloader,\n",
        "                    optimizer=optimizer,\n",
        "                    lr_scheduler=lr_scheduler,\n",
        "                    loss_fn=loss_fn, \n",
        "                    epochs=EPOCHS,\n",
        "                    eval_metrics=eval_metrics,\n",
        "                    writer=create_writer(experiment_name='NASDAQ100', model_name='dsa_rnn_model'))\n",
        "\n",
        "print(f\"Total fitting time: {timer()-start:.3f} seconds\")\n",
        "#print(model_results)"
      ],
      "metadata": {
        "id": "iprJFYTFeuES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Viewing TensorBoard in Jupyter and Google Colab Notebooks\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "9rn5nQVXeuCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test Data and Plotting\n",
        "test_loss, true_values, predicted_values = testing(model=dsa_rnn_model,\n",
        "                                                   dataloader=test_dataloader,\n",
        "                                                   loss_fn=loss_fn)\n",
        "\n",
        "#scale up the values -> they were downscaled at the beginning\n",
        "true_values = true_values*(target_train_max - target_train_min) + target_train_min\n",
        "predicted_values = predicted_values*(target_train_max - target_train_min) + target_train_min\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(18, 9))\n",
        "plt.title(f'[NASDAQ100] Time Series - Test Loss: {test_loss:.5f}')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Price')\n",
        "plt.plot(true_values, color='green', label='True')\n",
        "plt.plot(predicted_values, color='red', label='Predicted')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AhsJG9XYq_TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Experiment Tracking (This will take a long time)\n",
        "#Set random seeds\n",
        "torch.manual_seed(10) \n",
        "torch.cuda.manual_seed(10)\n",
        "\n",
        "#Experiment Parameters - These are the most important parameters from this paper\n",
        "num_EPOCHS = [1, 5, 10]\n",
        "N = X_train_t.shape[2] #81\n",
        "M_P_params = [16, 32, 64]\n",
        "T = 10 #can't be changed that easily -> the dataset is preprocessed with T = 10\n",
        "\n",
        "#start experiments\n",
        "for experiment_num, epoch in enumerate(num_EPOCHS, start=1):\n",
        "  for m_p_param in M_P_params:\n",
        "\n",
        "      print(f\"[INFO] Experiment number: {experiment_num}\")\n",
        "      print(f\"[INFO] M_P-Parameters: {m_p_param}\")\n",
        "      print(f\"[INFO] Number of epochs: {epoch}\")  \n",
        "\n",
        "      #Instantiate the model\n",
        "      dsa_rnn_model = DualStage_Attention_RNN(N, m_p_param, m_p_param, T).to(device)\n",
        "\n",
        "      #Define loss function and optimizer with learning rate decay\n",
        "      loss_fn = nn.MSELoss()\n",
        "      optimizer = optim.Adam(params=dsa_rnn_model.parameters(), lr=0.001)\n",
        "      lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=15, gamma=0.8)\n",
        "\n",
        "      #Evaluation Metrics\n",
        "      eval_metrics = [RMSELoss, nn.L1Loss(), MAPE()]\n",
        "\n",
        "      #start timer\n",
        "      start = timer()\n",
        "\n",
        "      fit(model=dsa_rnn_model, \n",
        "          train_dataloader=train_dataloader,\n",
        "          val_dataloader=val_dataloader,\n",
        "          optimizer=optimizer,\n",
        "          lr_scheduler=lr_scheduler,\n",
        "          loss_fn=loss_fn, \n",
        "          epochs=epoch,\n",
        "          eval_metrics=eval_metrics,\n",
        "          writer=create_writer(experiment_name='NASDAQ100', model_name='dsa_rnn_model', extra=f\"{epoch}_epochs\"))\n",
        "\n",
        "      print(f\"Total fitting time: {timer()-start:.3f} seconds\")\n",
        "\n",
        "      #save model state_dict\n",
        "      save_filepath = f\"dsa_rnn_model_NASDAQ100_{epoch}_epochs.pth\"\n",
        "      save_model(model=dsa_rnn_model,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=save_filepath)\n",
        "      print(\"-\"*35 + \"\\n\")"
      ],
      "metadata": {
        "id": "O7ElRmfNdMtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Viewing TensorBoard in Jupyter and Google Colab Notebooks\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "fFyw_fpshkeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the best model\n",
        "# Setup the best model filepath\n",
        "model_path = \".pth\" #Path needs to be filled in\n",
        "#create model with correct parameters\n",
        "model = DualStage_Attention_RNN() #Correct parameters need to be filled in\n",
        "#load model state_dict\n",
        "try:\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    print(\"Model loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Model file not found.\")\n",
        "\n",
        "test_loss, true_values, predicted_values = testing(model=model,\n",
        "                                                   dataloader=test_dataloader,\n",
        "                                                   loss_fn=loss_fn)\n",
        "\n",
        "#scale up the values -> they were downscaled at the beginning\n",
        "true_values = true_values*(target_train_max - target_train_min) + target_train_min\n",
        "predicted_values = predicted_values*(target_train_max - target_train_min) + target_train_min\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(18, 9))\n",
        "plt.title(f'[NASDAQ100] Time Series - Test Loss: {test_loss:.5f}')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.ylabel('Price')\n",
        "plt.plot(true_values, color='green', label='True')\n",
        "plt.plot(predicted_values, color='red', label='Predicted')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1s6Sa9jHiMoF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}